{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Path to the folder containing images\n",
    "good_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/good'\n",
    "bad_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/defective'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess images\n",
    "img_height, img_width = 128, 128\n",
    "good_tyre_images, good_tyre_labels = load_and_preprocess_images(good_tyre_path, label=0)\n",
    "bad_tyre_images, bad_tyre_labels = load_and_preprocess_images(bad_tyre_path, label=1)\n",
    "\n",
    "# Combine and shuffle the data\n",
    "all_images = np.concatenate((good_tyre_images, bad_tyre_images), axis=0)\n",
    "all_labels = np.concatenate((good_tyre_labels, bad_tyre_labels), axis=0)\n",
    "shuffle_indices = np.random.permutation(len(all_images))\n",
    "all_images = all_images[shuffle_indices]\n",
    "all_labels = all_labels[shuffle_indices]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(all_images) * split_ratio)\n",
    "\n",
    "train_data, train_labels = all_images[:split_index], all_labels[:split_index]\n",
    "val_data, val_labels = all_images[split_index:], all_labels[split_index:]\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for more epochs\n",
    "model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=50, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Save the model\n",
    "model.save('improved_cnn_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Path to the folder containing images\n",
    "good_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/good'\n",
    "bad_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/defective'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess images\n",
    "img_height, img_width = 128, 128\n",
    "good_tyre_images, good_tyre_labels = load_and_preprocess_images(good_tyre_path, label=0)\n",
    "bad_tyre_images, bad_tyre_labels = load_and_preprocess_images(bad_tyre_path, label=1)\n",
    "\n",
    "# Combine and shuffle the data\n",
    "all_images = np.concatenate((good_tyre_images, bad_tyre_images), axis=0)\n",
    "all_labels = np.concatenate((good_tyre_labels, bad_tyre_labels), axis=0)\n",
    "shuffle_indices = np.random.permutation(len(all_images))\n",
    "all_images = all_images[shuffle_indices]\n",
    "all_labels = all_labels[shuffle_indices]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(all_images) * split_ratio)\n",
    "\n",
    "train_data, train_labels = all_images[:split_index], all_labels[:split_index]\n",
    "val_data, val_labels = all_images[split_index:], all_labels[split_index:]\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load the VGG16 model with pre-trained weights\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary crossentropy\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with data augmentation\n",
    "model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=20, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Save the model in .h5 format\n",
    "model.save('transfer_learning_model.h5')\n",
    "\n",
    "# Evaluation on folders\n",
    "def evaluate_folder(folder_path, model):\n",
    "    normal_count = 0\n",
    "    cracked_count = 0\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_array = load_and_preprocess_image(img_path)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            prediction = model.predict(img_array)[0, 0]\n",
    "            predicted_class = 1 if prediction > 0.5 else 0\n",
    "\n",
    "            if predicted_class == 1:\n",
    "                cracked_count += 1\n",
    "            else:\n",
    "                normal_count += 1\n",
    "\n",
    "    print(f\"Total Cracked Tires: {cracked_count}\")\n",
    "    print(f\"Total Normal Tires: {normal_count}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T10:29:56.158982Z",
     "iopub.status.busy": "2024-01-21T10:29:56.158454Z",
     "iopub.status.idle": "2024-01-21T10:30:30.097051Z",
     "shell.execute_reply": "2024-01-21T10:30:30.096032Z",
     "shell.execute_reply.started": "2024-01-21T10:29:56.158947Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Total Cracked Tires: 27\n",
      "Total Normal Tires: 349\n",
      "[0.82300955, 0.9428467, 0.5190063, 0.60807484, 0.99555475, 0.8346801, 0.99044436, 0.8144256, 0.7628027, 0.68929857, 0.8948047, 0.9924213, 0.99902093, 0.9894162, 0.94532424, 0.58423644, 0.57446885, 0.7167496, 0.88265693, 0.98301053, 0.99466383, 0.91518044, 0.9106118, 0.5904066, 0.69559973, 0.6350307, 0.6202444]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Path to the folder containing images to be predicted\n",
    "prediction_folder = '/kaggle/input/tire-texture-image-recognition/Tire Textures/training_data/normal'\n",
    "\n",
    "# Path to the saved model\n",
    "model_path = '/kaggle/working/improved_cnn_model_v4.h5'  # Change this to the path where your saved model is located\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def load_and_preprocess_image(img_path, target_size=(128, 128)):\n",
    "    img = load_img(img_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Counters for normal and cracked predictions\n",
    "normal_count = 0\n",
    "cracked_count = 0\n",
    "\n",
    "error = []\n",
    "# Iterate through images in the prediction folder\n",
    "for filename in os.listdir(prediction_folder):\n",
    "    img_path = os.path.join(prediction_folder, filename)\n",
    "\n",
    "    # Check if the file is a valid image file\n",
    "    if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Load and preprocess the image\n",
    "        img_array = load_and_preprocess_image(img_path)\n",
    "\n",
    "        # Make predictions\n",
    "        prediction = model.predict(img_array)[0, 0]  # Extracting the scalar value from the prediction tensor\n",
    "\n",
    "        # Determine predicted class\n",
    "        predicted_class = 1 if prediction > 0.5 else 0\n",
    "\n",
    "        # Update counters\n",
    "        if predicted_class == 1:\n",
    "            cracked_count += 1\n",
    "            error.append(prediction)\n",
    "            \n",
    "        else:\n",
    "            normal_count += 1\n",
    "            \n",
    "\n",
    "# Display counts\n",
    "print(f\"Total Cracked Tires: {cracked_count}\")\n",
    "print(f\"Total Normal Tires: {normal_count}\")\n",
    "\n",
    "print(error)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T10:07:39.234632Z",
     "iopub.status.busy": "2024-01-21T10:07:39.234262Z",
     "iopub.status.idle": "2024-01-21T10:07:39.242476Z",
     "shell.execute_reply": "2024-01-21T10:07:39.241487Z",
     "shell.execute_reply.started": "2024-01-21T10:07:39.234602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064351875028569"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumn = 0\n",
    "for i in range(len(error)):\n",
    "    sumn += error[i]\n",
    "    \n",
    "    \n",
    "sumn / len(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T09:53:30.028701Z",
     "iopub.status.busy": "2024-01-21T09:53:30.028280Z",
     "iopub.status.idle": "2024-01-21T10:02:20.491651Z",
     "shell.execute_reply": "2024-01-21T10:02:20.490089Z",
     "shell.execute_reply.started": "2024-01-21T09:53:30.028670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "47/47 [==============================] - 13s 153ms/step - loss: 1.3249 - accuracy: 0.5472 - val_loss: 1.0299 - val_accuracy: 0.6102 - lr: 1.0000e-05\n",
      "Epoch 2/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 1.1071 - accuracy: 0.6119 - val_loss: 0.7151 - val_accuracy: 0.6371 - lr: 1.0000e-05\n",
      "Epoch 3/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.9771 - accuracy: 0.6233 - val_loss: 0.6433 - val_accuracy: 0.7070 - lr: 1.0000e-05\n",
      "Epoch 4/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.9183 - accuracy: 0.6368 - val_loss: 0.6393 - val_accuracy: 0.7151 - lr: 1.0000e-05\n",
      "Epoch 5/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.8552 - accuracy: 0.6617 - val_loss: 0.6625 - val_accuracy: 0.6962 - lr: 1.0000e-05\n",
      "Epoch 6/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.7706 - accuracy: 0.6772 - val_loss: 0.6116 - val_accuracy: 0.7446 - lr: 1.0000e-05\n",
      "Epoch 7/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.7607 - accuracy: 0.6718 - val_loss: 0.6016 - val_accuracy: 0.7419 - lr: 1.0000e-05\n",
      "Epoch 8/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.6912 - accuracy: 0.6840 - val_loss: 0.6301 - val_accuracy: 0.7339 - lr: 1.0000e-05\n",
      "Epoch 9/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.7353 - accuracy: 0.6759 - val_loss: 0.6969 - val_accuracy: 0.7043 - lr: 1.0000e-05\n",
      "Epoch 10/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.6591 - accuracy: 0.6941 - val_loss: 0.8452 - val_accuracy: 0.6505 - lr: 1.0000e-05\n",
      "Epoch 11/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.6430 - accuracy: 0.6880 - val_loss: 0.6239 - val_accuracy: 0.7231 - lr: 1.0000e-05\n",
      "Epoch 12/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.6479 - accuracy: 0.6934 - val_loss: 0.6179 - val_accuracy: 0.7177 - lr: 1.0000e-05\n",
      "Epoch 13/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.6077 - accuracy: 0.7156 - val_loss: 0.7406 - val_accuracy: 0.6801 - lr: 1.0000e-05\n",
      "Epoch 14/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.6327 - accuracy: 0.7170 - val_loss: 0.6179 - val_accuracy: 0.7258 - lr: 1.0000e-05\n",
      "Epoch 15/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.6071 - accuracy: 0.7015 - val_loss: 0.6460 - val_accuracy: 0.7312 - lr: 1.0000e-05\n",
      "Epoch 16/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.6105 - accuracy: 0.7163 - val_loss: 0.5934 - val_accuracy: 0.7312 - lr: 1.0000e-05\n",
      "Epoch 17/120\n",
      "47/47 [==============================] - 7s 138ms/step - loss: 0.5695 - accuracy: 0.7177 - val_loss: 0.5881 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 18/120\n",
      "47/47 [==============================] - 7s 139ms/step - loss: 0.6044 - accuracy: 0.7015 - val_loss: 0.5815 - val_accuracy: 0.7312 - lr: 1.0000e-05\n",
      "Epoch 19/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.5883 - accuracy: 0.7143 - val_loss: 0.5595 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 20/120\n",
      "47/47 [==============================] - 7s 139ms/step - loss: 0.5502 - accuracy: 0.7210 - val_loss: 0.6031 - val_accuracy: 0.7285 - lr: 1.0000e-05\n",
      "Epoch 21/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.5432 - accuracy: 0.7298 - val_loss: 0.5976 - val_accuracy: 0.7204 - lr: 1.0000e-05\n",
      "Epoch 22/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.5834 - accuracy: 0.7170 - val_loss: 0.6154 - val_accuracy: 0.7231 - lr: 1.0000e-05\n",
      "Epoch 23/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.5399 - accuracy: 0.7392 - val_loss: 0.5611 - val_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 24/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.5468 - accuracy: 0.7446 - val_loss: 0.6043 - val_accuracy: 0.7446 - lr: 1.0000e-05\n",
      "Epoch 25/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.5264 - accuracy: 0.7507 - val_loss: 0.6347 - val_accuracy: 0.7285 - lr: 1.0000e-05\n",
      "Epoch 26/120\n",
      "47/47 [==============================] - 7s 138ms/step - loss: 0.5194 - accuracy: 0.7446 - val_loss: 0.5570 - val_accuracy: 0.7527 - lr: 1.0000e-05\n",
      "Epoch 27/120\n",
      "47/47 [==============================] - 7s 139ms/step - loss: 0.5229 - accuracy: 0.7446 - val_loss: 0.6056 - val_accuracy: 0.7473 - lr: 1.0000e-05\n",
      "Epoch 28/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.5245 - accuracy: 0.7466 - val_loss: 0.5777 - val_accuracy: 0.7527 - lr: 1.0000e-05\n",
      "Epoch 29/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.5232 - accuracy: 0.7446 - val_loss: 0.6029 - val_accuracy: 0.7231 - lr: 1.0000e-05\n",
      "Epoch 30/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.5106 - accuracy: 0.7567 - val_loss: 0.6320 - val_accuracy: 0.7231 - lr: 1.0000e-05\n",
      "Epoch 31/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.5004 - accuracy: 0.7662 - val_loss: 0.5571 - val_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 32/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.5081 - accuracy: 0.7574 - val_loss: 0.5221 - val_accuracy: 0.7715 - lr: 1.0000e-05\n",
      "Epoch 33/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.5000 - accuracy: 0.7520 - val_loss: 0.5267 - val_accuracy: 0.7661 - lr: 1.0000e-05\n",
      "Epoch 34/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.5079 - accuracy: 0.7588 - val_loss: 0.5585 - val_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 35/120\n",
      "47/47 [==============================] - 7s 147ms/step - loss: 0.4956 - accuracy: 0.7487 - val_loss: 0.5631 - val_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 36/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4647 - accuracy: 0.7844 - val_loss: 0.5358 - val_accuracy: 0.7796 - lr: 1.0000e-05\n",
      "Epoch 37/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.4858 - accuracy: 0.7709 - val_loss: 0.5094 - val_accuracy: 0.7688 - lr: 1.0000e-05\n",
      "Epoch 38/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.4801 - accuracy: 0.7682 - val_loss: 0.5571 - val_accuracy: 0.7446 - lr: 1.0000e-05\n",
      "Epoch 39/120\n",
      "47/47 [==============================] - 7s 149ms/step - loss: 0.4844 - accuracy: 0.7662 - val_loss: 0.5189 - val_accuracy: 0.7688 - lr: 1.0000e-05\n",
      "Epoch 40/120\n",
      "47/47 [==============================] - 7s 150ms/step - loss: 0.4818 - accuracy: 0.7803 - val_loss: 0.5007 - val_accuracy: 0.7823 - lr: 1.0000e-05\n",
      "Epoch 41/120\n",
      "47/47 [==============================] - 7s 147ms/step - loss: 0.4837 - accuracy: 0.7817 - val_loss: 0.5327 - val_accuracy: 0.7715 - lr: 1.0000e-05\n",
      "Epoch 42/120\n",
      "47/47 [==============================] - 7s 158ms/step - loss: 0.5023 - accuracy: 0.7642 - val_loss: 0.5425 - val_accuracy: 0.7661 - lr: 1.0000e-05\n",
      "Epoch 43/120\n",
      "47/47 [==============================] - 7s 152ms/step - loss: 0.4647 - accuracy: 0.7891 - val_loss: 0.5376 - val_accuracy: 0.7742 - lr: 1.0000e-05\n",
      "Epoch 44/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.4679 - accuracy: 0.7837 - val_loss: 0.5441 - val_accuracy: 0.7769 - lr: 1.0000e-05\n",
      "Epoch 45/120\n",
      "47/47 [==============================] - 7s 152ms/step - loss: 0.4668 - accuracy: 0.7904 - val_loss: 0.5573 - val_accuracy: 0.7715 - lr: 1.0000e-05\n",
      "Epoch 46/120\n",
      "47/47 [==============================] - 7s 153ms/step - loss: 0.4435 - accuracy: 0.7972 - val_loss: 0.5468 - val_accuracy: 0.7796 - lr: 1.0000e-05\n",
      "Epoch 47/120\n",
      "47/47 [==============================] - 7s 149ms/step - loss: 0.4508 - accuracy: 0.7904 - val_loss: 0.5106 - val_accuracy: 0.7849 - lr: 1.0000e-05\n",
      "Epoch 48/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.4742 - accuracy: 0.7736 - val_loss: 0.4996 - val_accuracy: 0.7796 - lr: 1.0000e-05\n",
      "Epoch 49/120\n",
      "47/47 [==============================] - 7s 147ms/step - loss: 0.4388 - accuracy: 0.7817 - val_loss: 0.4983 - val_accuracy: 0.8011 - lr: 1.0000e-05\n",
      "Epoch 50/120\n",
      "47/47 [==============================] - 7s 147ms/step - loss: 0.4496 - accuracy: 0.8039 - val_loss: 0.4872 - val_accuracy: 0.7957 - lr: 1.0000e-05\n",
      "Epoch 51/120\n",
      "47/47 [==============================] - 7s 152ms/step - loss: 0.4362 - accuracy: 0.7999 - val_loss: 0.5620 - val_accuracy: 0.7661 - lr: 1.0000e-05\n",
      "Epoch 52/120\n",
      "47/47 [==============================] - 7s 152ms/step - loss: 0.4356 - accuracy: 0.7958 - val_loss: 0.5288 - val_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 53/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4286 - accuracy: 0.8005 - val_loss: 0.5041 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
      "Epoch 54/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4421 - accuracy: 0.8039 - val_loss: 0.4981 - val_accuracy: 0.7796 - lr: 1.0000e-05\n",
      "Epoch 55/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.4357 - accuracy: 0.8100 - val_loss: 0.4442 - val_accuracy: 0.8145 - lr: 1.0000e-05\n",
      "Epoch 56/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.4418 - accuracy: 0.8086 - val_loss: 0.4590 - val_accuracy: 0.8011 - lr: 1.0000e-05\n",
      "Epoch 57/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.4395 - accuracy: 0.7938 - val_loss: 0.4692 - val_accuracy: 0.8065 - lr: 1.0000e-05\n",
      "Epoch 58/120\n",
      " 6/47 [==>...........................] - ETA: 4s - loss: 0.4998 - accuracy: 0.7616"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     87\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimproved_cnn_model_v3.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Path to the folder containing images\n",
    "good_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/good'\n",
    "bad_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/defective'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess images\n",
    "img_height, img_width = 128, 128\n",
    "good_tyre_images, good_tyre_labels = load_and_preprocess_images(good_tyre_path, label=0)\n",
    "bad_tyre_images, bad_tyre_labels = load_and_preprocess_images(bad_tyre_path, label=1)\n",
    "\n",
    "# Combine and shuffle the data\n",
    "all_images = np.concatenate((good_tyre_images, bad_tyre_images), axis=0)\n",
    "all_labels = np.concatenate((good_tyre_labels, bad_tyre_labels), axis=0)\n",
    "shuffle_indices = np.random.permutation(len(all_images))\n",
    "all_images = all_images[shuffle_indices]\n",
    "all_labels = all_labels[shuffle_indices]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(all_images) * split_ratio)\n",
    "\n",
    "train_data, train_labels = all_images[:split_index], all_labels[:split_index]\n",
    "val_data, val_labels = all_images[split_index:], all_labels[split_index:]\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Use a learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.00001\n",
    "    if epoch > 60:\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Deeper Model with Batch Normalization and Increased Dropout\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=120,  \n",
    "          validation_data=(val_data, val_labels), callbacks=[lr_scheduler])\n",
    "\n",
    "# Save the model\n",
    "model.save('improved_cnn_model_v3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove('/kaggle/working/improved_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T10:09:00.819912Z",
     "iopub.status.busy": "2024-01-21T10:09:00.819036Z",
     "iopub.status.idle": "2024-01-21T10:23:50.534964Z",
     "shell.execute_reply": "2024-01-21T10:23:50.533878Z",
     "shell.execute_reply.started": "2024-01-21T10:09:00.819876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "47/47 [==============================] - 10s 149ms/step - loss: 1.7143 - accuracy: 0.6220 - val_loss: 0.6594 - val_accuracy: 0.7097 - lr: 1.0000e-04\n",
      "Epoch 2/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 1.0904 - accuracy: 0.6449 - val_loss: 0.5987 - val_accuracy: 0.7312 - lr: 1.0000e-04\n",
      "Epoch 3/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.6887 - accuracy: 0.6853 - val_loss: 0.5318 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 4/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.6107 - accuracy: 0.7136 - val_loss: 0.4995 - val_accuracy: 0.7957 - lr: 1.0000e-04\n",
      "Epoch 5/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.5920 - accuracy: 0.7156 - val_loss: 0.4693 - val_accuracy: 0.7823 - lr: 1.0000e-04\n",
      "Epoch 6/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.5520 - accuracy: 0.7358 - val_loss: 0.5623 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 7/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.5388 - accuracy: 0.7352 - val_loss: 0.4405 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 8/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.5375 - accuracy: 0.7480 - val_loss: 0.4337 - val_accuracy: 0.8118 - lr: 1.0000e-04\n",
      "Epoch 9/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.4928 - accuracy: 0.7574 - val_loss: 0.4112 - val_accuracy: 0.8253 - lr: 1.0000e-04\n",
      "Epoch 10/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.4898 - accuracy: 0.7628 - val_loss: 0.5055 - val_accuracy: 0.7876 - lr: 1.0000e-04\n",
      "Epoch 11/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4778 - accuracy: 0.7749 - val_loss: 0.4819 - val_accuracy: 0.8091 - lr: 1.0000e-04\n",
      "Epoch 12/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.4878 - accuracy: 0.7783 - val_loss: 0.4402 - val_accuracy: 0.8306 - lr: 1.0000e-04\n",
      "Epoch 13/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.4522 - accuracy: 0.7844 - val_loss: 0.5459 - val_accuracy: 0.7796 - lr: 1.0000e-04\n",
      "Epoch 14/120\n",
      "47/47 [==============================] - 7s 139ms/step - loss: 0.4386 - accuracy: 0.7999 - val_loss: 0.4524 - val_accuracy: 0.8065 - lr: 1.0000e-04\n",
      "Epoch 15/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.4227 - accuracy: 0.8187 - val_loss: 0.4628 - val_accuracy: 0.7849 - lr: 1.0000e-04\n",
      "Epoch 16/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4241 - accuracy: 0.8012 - val_loss: 0.4055 - val_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 17/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4142 - accuracy: 0.8140 - val_loss: 1.1050 - val_accuracy: 0.5376 - lr: 1.0000e-04\n",
      "Epoch 18/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.4218 - accuracy: 0.8066 - val_loss: 1.0459 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 19/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.4033 - accuracy: 0.8255 - val_loss: 0.5221 - val_accuracy: 0.7769 - lr: 1.0000e-04\n",
      "Epoch 20/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.3836 - accuracy: 0.8322 - val_loss: 0.9065 - val_accuracy: 0.6532 - lr: 1.0000e-04\n",
      "Epoch 21/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.3711 - accuracy: 0.8369 - val_loss: 0.4343 - val_accuracy: 0.8306 - lr: 1.0000e-04\n",
      "Epoch 22/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.3564 - accuracy: 0.8423 - val_loss: 0.6259 - val_accuracy: 0.7849 - lr: 1.0000e-04\n",
      "Epoch 23/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.3527 - accuracy: 0.8363 - val_loss: 0.5683 - val_accuracy: 0.7984 - lr: 1.0000e-04\n",
      "Epoch 24/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.3502 - accuracy: 0.8484 - val_loss: 0.4835 - val_accuracy: 0.8280 - lr: 1.0000e-04\n",
      "Epoch 25/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.3455 - accuracy: 0.8470 - val_loss: 0.4586 - val_accuracy: 0.8414 - lr: 1.0000e-04\n",
      "Epoch 26/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.3281 - accuracy: 0.8571 - val_loss: 0.4031 - val_accuracy: 0.8306 - lr: 1.0000e-04\n",
      "Epoch 27/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.3373 - accuracy: 0.8544 - val_loss: 0.4921 - val_accuracy: 0.7957 - lr: 1.0000e-04\n",
      "Epoch 28/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.3138 - accuracy: 0.8720 - val_loss: 0.4690 - val_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 29/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.3098 - accuracy: 0.8801 - val_loss: 0.8045 - val_accuracy: 0.7634 - lr: 1.0000e-04\n",
      "Epoch 30/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.3731 - accuracy: 0.8383 - val_loss: 0.4695 - val_accuracy: 0.8253 - lr: 1.0000e-04\n",
      "Epoch 31/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.3385 - accuracy: 0.8504 - val_loss: 0.3957 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
      "Epoch 32/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.3045 - accuracy: 0.8686 - val_loss: 0.5103 - val_accuracy: 0.8199 - lr: 1.0000e-04\n",
      "Epoch 33/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.3280 - accuracy: 0.8652 - val_loss: 2.0724 - val_accuracy: 0.5403 - lr: 1.0000e-04\n",
      "Epoch 34/120\n",
      "47/47 [==============================] - 7s 148ms/step - loss: 0.3080 - accuracy: 0.8706 - val_loss: 0.3486 - val_accuracy: 0.8495 - lr: 1.0000e-04\n",
      "Epoch 35/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2972 - accuracy: 0.8787 - val_loss: 0.5289 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 36/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2999 - accuracy: 0.8767 - val_loss: 0.4069 - val_accuracy: 0.8575 - lr: 1.0000e-04\n",
      "Epoch 37/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.2820 - accuracy: 0.8747 - val_loss: 1.1598 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
      "Epoch 38/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2557 - accuracy: 0.9009 - val_loss: 0.3176 - val_accuracy: 0.8844 - lr: 1.0000e-04\n",
      "Epoch 39/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.2606 - accuracy: 0.8888 - val_loss: 0.6694 - val_accuracy: 0.7823 - lr: 1.0000e-04\n",
      "Epoch 40/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2669 - accuracy: 0.8848 - val_loss: 0.3921 - val_accuracy: 0.8629 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.2881 - accuracy: 0.8848 - val_loss: 0.3816 - val_accuracy: 0.8602 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2741 - accuracy: 0.8888 - val_loss: 0.7306 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "47/47 [==============================] - 7s 148ms/step - loss: 0.2603 - accuracy: 0.8956 - val_loss: 0.4126 - val_accuracy: 0.8522 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.2373 - accuracy: 0.8942 - val_loss: 0.3954 - val_accuracy: 0.8629 - lr: 1.0000e-04\n",
      "Epoch 45/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.2401 - accuracy: 0.8956 - val_loss: 0.6693 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 46/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.2806 - accuracy: 0.8881 - val_loss: 2.6582 - val_accuracy: 0.5188 - lr: 1.0000e-04\n",
      "Epoch 47/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.2578 - accuracy: 0.8976 - val_loss: 0.4047 - val_accuracy: 0.8575 - lr: 1.0000e-04\n",
      "Epoch 48/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.2371 - accuracy: 0.9036 - val_loss: 1.4004 - val_accuracy: 0.6478 - lr: 1.0000e-04\n",
      "Epoch 49/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2260 - accuracy: 0.9090 - val_loss: 0.3298 - val_accuracy: 0.8763 - lr: 1.0000e-04\n",
      "Epoch 50/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.2231 - accuracy: 0.9077 - val_loss: 1.8622 - val_accuracy: 0.5726 - lr: 1.0000e-04\n",
      "Epoch 51/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2456 - accuracy: 0.8976 - val_loss: 0.4255 - val_accuracy: 0.8710 - lr: 1.0000e-04\n",
      "Epoch 52/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.2267 - accuracy: 0.9111 - val_loss: 0.3712 - val_accuracy: 0.8737 - lr: 1.0000e-04\n",
      "Epoch 53/120\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.2314 - accuracy: 0.9050 - val_loss: 0.8774 - val_accuracy: 0.6935 - lr: 1.0000e-04\n",
      "Epoch 54/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2369 - accuracy: 0.9043 - val_loss: 0.3341 - val_accuracy: 0.8737 - lr: 1.0000e-04\n",
      "Epoch 55/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.2229 - accuracy: 0.9111 - val_loss: 0.3575 - val_accuracy: 0.8763 - lr: 1.0000e-04\n",
      "Epoch 56/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.2302 - accuracy: 0.9131 - val_loss: 0.4489 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
      "Epoch 57/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.2071 - accuracy: 0.9239 - val_loss: 0.3724 - val_accuracy: 0.8844 - lr: 1.0000e-04\n",
      "Epoch 58/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.2174 - accuracy: 0.9097 - val_loss: 0.7882 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 59/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.2222 - accuracy: 0.9178 - val_loss: 0.5731 - val_accuracy: 0.7930 - lr: 1.0000e-04\n",
      "Epoch 60/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2033 - accuracy: 0.9178 - val_loss: 0.5401 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
      "Epoch 61/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.2192 - accuracy: 0.9144 - val_loss: 0.6308 - val_accuracy: 0.7769 - lr: 1.0000e-04\n",
      "Epoch 62/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1986 - accuracy: 0.9212 - val_loss: 0.2966 - val_accuracy: 0.8925 - lr: 1.0000e-05\n",
      "Epoch 63/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1553 - accuracy: 0.9394 - val_loss: 0.2398 - val_accuracy: 0.9140 - lr: 1.0000e-05\n",
      "Epoch 64/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1521 - accuracy: 0.9373 - val_loss: 0.2347 - val_accuracy: 0.9194 - lr: 1.0000e-05\n",
      "Epoch 65/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1431 - accuracy: 0.9481 - val_loss: 0.2569 - val_accuracy: 0.9194 - lr: 1.0000e-05\n",
      "Epoch 66/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1666 - accuracy: 0.9313 - val_loss: 0.2515 - val_accuracy: 0.9247 - lr: 1.0000e-05\n",
      "Epoch 67/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1461 - accuracy: 0.9468 - val_loss: 0.2564 - val_accuracy: 0.9301 - lr: 1.0000e-05\n",
      "Epoch 68/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1355 - accuracy: 0.9454 - val_loss: 0.2629 - val_accuracy: 0.9220 - lr: 1.0000e-05\n",
      "Epoch 69/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1547 - accuracy: 0.9353 - val_loss: 0.2575 - val_accuracy: 0.9247 - lr: 1.0000e-05\n",
      "Epoch 70/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1347 - accuracy: 0.9481 - val_loss: 0.2604 - val_accuracy: 0.9247 - lr: 1.0000e-05\n",
      "Epoch 71/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1245 - accuracy: 0.9488 - val_loss: 0.2875 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 72/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1475 - accuracy: 0.9394 - val_loss: 0.2762 - val_accuracy: 0.9194 - lr: 1.0000e-05\n",
      "Epoch 73/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1353 - accuracy: 0.9528 - val_loss: 0.2797 - val_accuracy: 0.9194 - lr: 1.0000e-05\n",
      "Epoch 74/120\n",
      "47/47 [==============================] - 7s 139ms/step - loss: 0.1411 - accuracy: 0.9468 - val_loss: 0.2889 - val_accuracy: 0.9140 - lr: 1.0000e-05\n",
      "Epoch 75/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1351 - accuracy: 0.9495 - val_loss: 0.2969 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 76/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1286 - accuracy: 0.9488 - val_loss: 0.2909 - val_accuracy: 0.9140 - lr: 1.0000e-05\n",
      "Epoch 77/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1265 - accuracy: 0.9495 - val_loss: 0.3302 - val_accuracy: 0.8925 - lr: 1.0000e-05\n",
      "Epoch 78/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.1181 - accuracy: 0.9582 - val_loss: 0.2889 - val_accuracy: 0.9113 - lr: 1.0000e-05\n",
      "Epoch 79/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.1335 - accuracy: 0.9495 - val_loss: 0.2884 - val_accuracy: 0.9086 - lr: 1.0000e-05\n",
      "Epoch 80/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1283 - accuracy: 0.9441 - val_loss: 0.3060 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 81/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1178 - accuracy: 0.9569 - val_loss: 0.3120 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 82/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1282 - accuracy: 0.9549 - val_loss: 0.3313 - val_accuracy: 0.8871 - lr: 1.0000e-05\n",
      "Epoch 83/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1155 - accuracy: 0.9589 - val_loss: 0.3062 - val_accuracy: 0.9086 - lr: 1.0000e-05\n",
      "Epoch 84/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.1330 - accuracy: 0.9508 - val_loss: 0.2820 - val_accuracy: 0.9113 - lr: 1.0000e-05\n",
      "Epoch 85/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1262 - accuracy: 0.9522 - val_loss: 0.3018 - val_accuracy: 0.8978 - lr: 1.0000e-05\n",
      "Epoch 86/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1368 - accuracy: 0.9461 - val_loss: 0.3205 - val_accuracy: 0.9032 - lr: 1.0000e-05\n",
      "Epoch 87/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1256 - accuracy: 0.9474 - val_loss: 0.3251 - val_accuracy: 0.8898 - lr: 1.0000e-05\n",
      "Epoch 88/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1169 - accuracy: 0.9535 - val_loss: 0.3805 - val_accuracy: 0.8817 - lr: 1.0000e-05\n",
      "Epoch 89/120\n",
      "47/47 [==============================] - 7s 147ms/step - loss: 0.1159 - accuracy: 0.9535 - val_loss: 0.3290 - val_accuracy: 0.8871 - lr: 1.0000e-05\n",
      "Epoch 90/120\n",
      "47/47 [==============================] - 7s 147ms/step - loss: 0.1160 - accuracy: 0.9555 - val_loss: 0.3092 - val_accuracy: 0.9086 - lr: 1.0000e-05\n",
      "Epoch 91/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1162 - accuracy: 0.9596 - val_loss: 0.3126 - val_accuracy: 0.8978 - lr: 1.0000e-05\n",
      "Epoch 92/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1056 - accuracy: 0.9609 - val_loss: 0.3153 - val_accuracy: 0.8952 - lr: 1.0000e-05\n",
      "Epoch 93/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1099 - accuracy: 0.9575 - val_loss: 0.3084 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 94/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1221 - accuracy: 0.9569 - val_loss: 0.3101 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 95/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1303 - accuracy: 0.9427 - val_loss: 0.2999 - val_accuracy: 0.9032 - lr: 1.0000e-05\n",
      "Epoch 96/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1102 - accuracy: 0.9528 - val_loss: 0.2994 - val_accuracy: 0.8978 - lr: 1.0000e-05\n",
      "Epoch 97/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1243 - accuracy: 0.9522 - val_loss: 0.2999 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 98/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1080 - accuracy: 0.9616 - val_loss: 0.2900 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 99/120\n",
      "47/47 [==============================] - 7s 148ms/step - loss: 0.1113 - accuracy: 0.9602 - val_loss: 0.3429 - val_accuracy: 0.8925 - lr: 1.0000e-05\n",
      "Epoch 100/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1048 - accuracy: 0.9589 - val_loss: 0.3311 - val_accuracy: 0.9032 - lr: 1.0000e-05\n",
      "Epoch 101/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1252 - accuracy: 0.9522 - val_loss: 0.3242 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 102/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1243 - accuracy: 0.9495 - val_loss: 0.3390 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 103/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1045 - accuracy: 0.9596 - val_loss: 0.3117 - val_accuracy: 0.9086 - lr: 1.0000e-05\n",
      "Epoch 104/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.1075 - accuracy: 0.9589 - val_loss: 0.3408 - val_accuracy: 0.8871 - lr: 1.0000e-05\n",
      "Epoch 105/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1131 - accuracy: 0.9616 - val_loss: 0.3380 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 106/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1048 - accuracy: 0.9602 - val_loss: 0.3141 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 107/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1005 - accuracy: 0.9609 - val_loss: 0.3671 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
      "Epoch 108/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1024 - accuracy: 0.9616 - val_loss: 0.3528 - val_accuracy: 0.8898 - lr: 1.0000e-05\n",
      "Epoch 109/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.0965 - accuracy: 0.9650 - val_loss: 0.3243 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 110/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.0981 - accuracy: 0.9609 - val_loss: 0.3311 - val_accuracy: 0.9086 - lr: 1.0000e-05\n",
      "Epoch 111/120\n",
      "47/47 [==============================] - 7s 141ms/step - loss: 0.1067 - accuracy: 0.9582 - val_loss: 0.3395 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 112/120\n",
      "47/47 [==============================] - 7s 145ms/step - loss: 0.1078 - accuracy: 0.9582 - val_loss: 0.4119 - val_accuracy: 0.8737 - lr: 1.0000e-05\n",
      "Epoch 113/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.0984 - accuracy: 0.9609 - val_loss: 0.3383 - val_accuracy: 0.8978 - lr: 1.0000e-05\n",
      "Epoch 114/120\n",
      "47/47 [==============================] - 7s 144ms/step - loss: 0.0942 - accuracy: 0.9656 - val_loss: 0.3650 - val_accuracy: 0.8871 - lr: 1.0000e-05\n",
      "Epoch 115/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.1068 - accuracy: 0.9555 - val_loss: 0.3187 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 116/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.0937 - accuracy: 0.9636 - val_loss: 0.3621 - val_accuracy: 0.8898 - lr: 1.0000e-05\n",
      "Epoch 117/120\n",
      "47/47 [==============================] - 7s 148ms/step - loss: 0.1033 - accuracy: 0.9602 - val_loss: 0.4431 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Epoch 118/120\n",
      "47/47 [==============================] - 7s 146ms/step - loss: 0.1089 - accuracy: 0.9602 - val_loss: 0.3423 - val_accuracy: 0.9032 - lr: 1.0000e-05\n",
      "Epoch 119/120\n",
      "47/47 [==============================] - 7s 143ms/step - loss: 0.0975 - accuracy: 0.9690 - val_loss: 0.3309 - val_accuracy: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 120/120\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.0868 - accuracy: 0.9677 - val_loss: 0.3150 - val_accuracy: 0.9113 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Path to the folder containing images\n",
    "good_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/good'\n",
    "bad_tyre_path = '/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres/defective'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(folder_path, label, target_size=(128, 128)): \n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess images\n",
    "good_tyre_images, good_tyre_labels = load_and_preprocess_images(good_tyre_path, label=0)\n",
    "bad_tyre_images, bad_tyre_labels = load_and_preprocess_images(bad_tyre_path, label=1)\n",
    "\n",
    "# Combine and shuffle the data\n",
    "all_images = np.concatenate((good_tyre_images, bad_tyre_images), axis=0)\n",
    "all_labels = np.concatenate((good_tyre_labels, bad_tyre_labels), axis=0)\n",
    "shuffle_indices = np.random.permutation(len(all_images))\n",
    "all_images = all_images[shuffle_indices]\n",
    "all_labels = all_labels[shuffle_indices]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(all_images) * split_ratio)\n",
    "\n",
    "train_data, train_labels = all_images[:split_index], all_labels[:split_index]\n",
    "val_data, val_labels = all_images[split_index:], all_labels[split_index:]\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Use a learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.0001\n",
    "    if epoch > 60:\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Deeper Model with Batch Normalization and Increased Dropout\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(datagen.flow(train_data, train_labels, batch_size=32), epochs=120,  \n",
    "          validation_data=(val_data, val_labels), callbacks=[lr_scheduler])\n",
    "\n",
    "# Save the model\n",
    "model.save('dude.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 03:20:44.598693: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-05 03:20:44.776815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 03:20:44.776942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 03:20:44.803356: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 03:20:44.867914: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-05 03:20:44.869247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 03:20:45.869537: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-05 03:20:47.623055: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-03-05 03:20:47.623083: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: karthik-Aspire-A715-42G\n",
      "2024-03-05 03:20:47.623087: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: karthik-Aspire-A715-42G\n",
      "2024-03-05 03:20:47.623171: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.154.5\n",
      "2024-03-05 03:20:47.623184: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.154.5\n",
      "2024-03-05 03:20:47.623187: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.154.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n",
      "Predicted: Normal Tire\n",
      "3.0470113e-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Path to the saved model\n",
    "model_path = 'dude.h5'  # Change this to the path where your saved model is located\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def load_and_preprocess_image(img_path, target_size=(128, 128)):\n",
    "    img = load_img(img_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = '/home/karthik/Desktop/CNN/catdog/dataset/training_set/normal/NewNormal62.jpg'\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_array = load_and_preprocess_image(image_path)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(img_array)[0, 0]  # Extracting the scalar value from the prediction tensor\n",
    "\n",
    "# Determine predicted class\n",
    "predicted_class = 1 if prediction > 0.5 else 0\n",
    "\n",
    "# Display the prediction result\n",
    "if predicted_class == 1:\n",
    "    print(\"Predicted: Cracked Tire\")\n",
    "else:\n",
    "    print(\"Predicted: Normal Tire\")\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1731575,
     "sourceId": 2830785,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3741807,
     "sourceId": 6477184,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
